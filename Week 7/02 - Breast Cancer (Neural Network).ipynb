{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Introduction #2\n",
    "\n",
    "This exercise is adapted from https://www.springboard.com/blog/beginners-guide-neural-network-in-python-scikit-learn-0-18/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use SciKit Learn's built in Breast Cancer Data Set which has several features of tumors with a labeled class indicating whether the tumor was Malignant or Benign. We will try to create a neural network model that can take in these features and attempt to predict malignant or benign labels for tumors it has not seen before. Let's go ahead and start by getting the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer2 = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\kah_chen_chan\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the dataframe - what are the first few rows of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the attributes in the dataset\n",
    "cancer2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cancer = pd.read_csv('data/breast.csv')\n",
    "\n",
    "#df = pd.DataFrame(cancer2['target_names'],columns=cancer2['feature_names'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.drop(columns=['Unnamed: 32','id'], inplace=True)\n",
    "cancer.dropna(inplace=True)\n",
    "y=cancer.pop('diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "radius_mean              569.0   14.127292    3.524049    6.981000   \n",
       "texture_mean             569.0   19.289649    4.301036    9.710000   \n",
       "perimeter_mean           569.0   91.969033   24.298981   43.790000   \n",
       "area_mean                569.0  654.889104  351.914129  143.500000   \n",
       "smoothness_mean          569.0    0.096360    0.014064    0.052630   \n",
       "compactness_mean         569.0    0.104341    0.052813    0.019380   \n",
       "concavity_mean           569.0    0.088799    0.079720    0.000000   \n",
       "concave points_mean      569.0    0.048919    0.038803    0.000000   \n",
       "symmetry_mean            569.0    0.181162    0.027414    0.106000   \n",
       "fractal_dimension_mean   569.0    0.062798    0.007060    0.049960   \n",
       "radius_se                569.0    0.405172    0.277313    0.111500   \n",
       "texture_se               569.0    1.216853    0.551648    0.360200   \n",
       "perimeter_se             569.0    2.866059    2.021855    0.757000   \n",
       "area_se                  569.0   40.337079   45.491006    6.802000   \n",
       "smoothness_se            569.0    0.007041    0.003003    0.001713   \n",
       "compactness_se           569.0    0.025478    0.017908    0.002252   \n",
       "concavity_se             569.0    0.031894    0.030186    0.000000   \n",
       "concave points_se        569.0    0.011796    0.006170    0.000000   \n",
       "symmetry_se              569.0    0.020542    0.008266    0.007882   \n",
       "fractal_dimension_se     569.0    0.003795    0.002646    0.000895   \n",
       "radius_worst             569.0   16.269190    4.833242    7.930000   \n",
       "texture_worst            569.0   25.677223    6.146258   12.020000   \n",
       "perimeter_worst          569.0  107.261213   33.602542   50.410000   \n",
       "area_worst               569.0  880.583128  569.356993  185.200000   \n",
       "smoothness_worst         569.0    0.132369    0.022832    0.071170   \n",
       "compactness_worst        569.0    0.254265    0.157336    0.027290   \n",
       "concavity_worst          569.0    0.272188    0.208624    0.000000   \n",
       "concave points_worst     569.0    0.114606    0.065732    0.000000   \n",
       "symmetry_worst           569.0    0.290076    0.061867    0.156500   \n",
       "fractal_dimension_worst  569.0    0.083946    0.018061    0.055040   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "radius_mean               11.700000   13.370000    15.780000    28.11000  \n",
       "texture_mean              16.170000   18.840000    21.800000    39.28000  \n",
       "perimeter_mean            75.170000   86.240000   104.100000   188.50000  \n",
       "area_mean                420.300000  551.100000   782.700000  2501.00000  \n",
       "smoothness_mean            0.086370    0.095870     0.105300     0.16340  \n",
       "compactness_mean           0.064920    0.092630     0.130400     0.34540  \n",
       "concavity_mean             0.029560    0.061540     0.130700     0.42680  \n",
       "concave points_mean        0.020310    0.033500     0.074000     0.20120  \n",
       "symmetry_mean              0.161900    0.179200     0.195700     0.30400  \n",
       "fractal_dimension_mean     0.057700    0.061540     0.066120     0.09744  \n",
       "radius_se                  0.232400    0.324200     0.478900     2.87300  \n",
       "texture_se                 0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter_se               1.606000    2.287000     3.357000    21.98000  \n",
       "area_se                   17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness_se              0.005169    0.006380     0.008146     0.03113  \n",
       "compactness_se             0.013080    0.020450     0.032450     0.13540  \n",
       "concavity_se               0.015090    0.025890     0.042050     0.39600  \n",
       "concave points_se          0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry_se                0.015160    0.018730     0.023480     0.07895  \n",
       "fractal_dimension_se       0.002248    0.003187     0.004558     0.02984  \n",
       "radius_worst              13.010000   14.970000    18.790000    36.04000  \n",
       "texture_worst             21.080000   25.410000    29.720000    49.54000  \n",
       "perimeter_worst           84.110000   97.660000   125.400000   251.20000  \n",
       "area_worst               515.300000  686.500000  1084.000000  4254.00000  \n",
       "smoothness_worst           0.116600    0.131300     0.146000     0.22260  \n",
       "compactness_worst          0.147200    0.211900     0.339100     1.05800  \n",
       "concavity_worst            0.114500    0.226700     0.382900     1.25200  \n",
       "concave points_worst       0.064930    0.099930     0.161400     0.29100  \n",
       "symmetry_worst             0.250400    0.282200     0.317900     0.66380  \n",
       "fractal_dimension_worst    0.071460    0.080040     0.092080     0.20750  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe to find out more about the data\n",
    "cancer.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** what can you say about this dataset?\n",
    "\n",
    "Now, set up the data (x) and labels (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=cancer\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    " \n",
    "Let's split our data into training and testing sets, this is done easily with SciKit Learn's train_test_split function from model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    " \n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results. There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the StandardScalar library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    " \n",
    "Now it is time to train our model. SciKit Learn makes this incredibly easy, by using estimator objects. In this case we will import our estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the model, there are a lot of parameters you can choose to define and customize here, we will only define the hidden_layer_sizes. For this parameter you pass in a tuple consisting of the number of neurons you want at each layer, where the nth entry in the tuple represents the number of neurons in the nth layer of the MLP model. There are many ways to choose these numbers, but for simplicity we will choose 3 layers with the same number of neurons as there are features in our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Multilayerperceptron classifier and call it mlp\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been made we can fit the training data to our model, remember that this data has already been processed and scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you see in the output? What does it tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation\n",
    " \n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  5]\n",
      " [ 3 51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.94      0.95        89\n",
      "           M       0.91      0.94      0.93        54\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.94      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** what conclusion can you make from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and biases\n",
    "\n",
    "The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
    "\n",
    "To extract the MLP weights and biases after training your model, you use its public attributes coefs_ and intercepts_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficient values and interpret it\n",
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the intercepts values and interpret it\n",
    "mlp.intercepts_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you understand from the two values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional optional tasks...\n",
    "\n",
    "select a few known supervised techniques and compare their performance. Use 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
